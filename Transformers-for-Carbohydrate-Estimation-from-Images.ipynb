{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8460d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import ViTFeatureExtractor\n",
    "from transformers import ViTForImageClassification\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from google.colab import drive\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "model_name_or_path = 'google/vit-base-patch16-224'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "# model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31484b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funció per retallar imatge i reduïr el tamany de la imatge\n",
    "# Es retalla abans de guardar-la com a variable per tal de reduïr la memòria RAM ocupada. La relació d'aspecte es conserva.\n",
    "\n",
    "def crop_area(img0, imgf_width, imgf_height):\n",
    "\n",
    "    imgf_res = imgf_width/imgf_height\n",
    "    img0_width = img0.size[0]\n",
    "    img0_height = img0.size[1]\n",
    "    img0_res = img0_width/img0_height\n",
    "\n",
    "    if imgf_res < img0_res:\n",
    "\n",
    "      # Retallar amplada\n",
    "      # En píxels: area = (left, upper, right, lower)\n",
    "        cut_dist_side = (img0_width - (img0_height * imgf_res)) / 2.0\n",
    "        area = (round(cut_dist_side,0), 0, round(img0_width - cut_dist_side,0), img0_height)\n",
    "        img = img0.crop(area)\n",
    "\n",
    "    if imgf_res > img0_res:\n",
    "\n",
    "      # Retallar altura\n",
    "      # En píxels: area = (left, upper, right, lower)\n",
    "        cut_dist_height = (img0_height - (img0_width / imgf_res)) / 2.0\n",
    "        area = (0, round(cut_dist_height,0), img0_width, round(img0_height - cut_dist_height, 0))\n",
    "        img = img0.crop(area)\n",
    "\n",
    "    else:\n",
    "    area = (0,0,img0_width,img0_height)\n",
    "\n",
    "    return img.resize((imgf_width,imgf_height), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee471c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funció per obtenir les imatges de la base de dades i guardar-les a una variable diccionari\n",
    "def afegir_imatges(divisio,id):\n",
    "    camera = ['A','B','C','D']\n",
    "    dicc_im_id = {'A': [], 'B': [], 'C': [], 'D': []}\n",
    "\n",
    "    for i in range(len(camera)):\n",
    "    llista_camera = []\n",
    "    capture = cv2.VideoCapture('https://storage.googleapis.com/nutrition5k_dataset/nutrition5k_dataset/imagery/side_angles/' + id + '/camera_' + camera[i] + '.h264')\n",
    "    cont = 0\n",
    "    num_frames = 0\n",
    "    # path = ''\n",
    "\n",
    "    while (capture.isOpened()):\n",
    "        ret, frame = capture.read()\n",
    "        if (ret == True):\n",
    "\n",
    "            im = Image.fromarray(frame)\n",
    "            # im = crop_area(im,224,224)\n",
    "            llista_camera.append(im)\n",
    "            # llista_camera.append(Image.fromarray(crop_area(frame,224,224)))\n",
    "\n",
    "\n",
    "            cont += 1\n",
    "            if (cv2.waitKey(1) == ord('s')):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    dicc_im_id[camera[i]] = llista_camera\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    dir_im = {'A': dicc_im_id['A'], 'B': dicc_im_id['B'], 'C': dicc_im_id['C'], 'D': dicc_im_id['D']}\n",
    "    divisio.append(dir_im)\n",
    "\n",
    "# Repartir les imatges en els subconjunts d'entrenament, validació i test\n",
    "def repartir_mostres(diccionari,dtset):\n",
    "\n",
    "    n = 9\n",
    "\n",
    "    for i in range(len(diccionari['im'])):\n",
    "        for j in range(len(diccionari['im'][i])):\n",
    "            camera = ['A','B','C','D']\n",
    "            for k,x in enumerate(diccionari['im'][i][camera[j]]):\n",
    "                if k % n == 0:\n",
    "                    dtset['val']['image'].append(dicc['im'][i][camera[j]][k])\n",
    "                    dtset['val']['cho'].append(dicc['cho'][i])\n",
    "                if k % (n+1) == 0:\n",
    "                    dtset['test']['image'].append(dicc['im'][i][camera[j]][k])\n",
    "                    dtset['test']['cho'].append(dicc['cho'][i])\n",
    "                else:\n",
    "                    dtset['train']['image'].append(dicc['im'][i][camera[j]][k])\n",
    "                    dtset['train']['cho'].append(dicc['cho'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el diccionari\n",
    "dicc = {'id': [], 'cho': [], 'im': []}\n",
    "\n",
    "# Obtenir arxiu csv on es relaciona cada id de cada plat amb els CHO que continguin\n",
    "csv = pd.read_csv('https://storage.googleapis.com/nutrition5k_dataset/nutrition5k_dataset/metadata/dish_metadata_cafe1.csv', on_bad_lines='skip', header=None)\n",
    "\n",
    "# Número total de mostres\n",
    "len_dtset = len(csv)\n",
    "\n",
    "# Afegir ids i cho al diccionari\n",
    "for i in range(len_dtset):\n",
    "    dicc['id'].append(csv[0][i])\n",
    "    dicc['cho'].append(round((csv[4][i]*(1.0/100.0)-1.0),4))\n",
    "\n",
    "# Afegir les imatges\n",
    "for i in range(70):\n",
    "    afegir_imatges(dicc['im'],dicc['id'][i])\n",
    "\n",
    "# Creació del diccionari per a cada partició (train, validation, test)\n",
    "feattr = {'image': [], 'cho': []}\n",
    "featva = {'image': [], 'cho': []}\n",
    "featte = {'image': [], 'cho': []}\n",
    "\n",
    "# Creació del dataset a partir de les particions\n",
    "dtset = {'train': feattr, 'val': featva, 'test': featte}\n",
    "\n",
    "# Repartir les imatges a cada partició\n",
    "repartir_mostres(dicc,dtset)\n",
    "\n",
    "# Alliberar memòria eliminant el primer diccionari\n",
    "del(dicc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a15b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzar un conjunt d'imatges del dataset\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "fig = plt.figure(figsize=(16., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 4),  # creates 2x2 grid of axes,\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, [dtset['train']['image'][120], dtset['train']['image'][690], dtset['train']['image'][740],\n",
    "                         dtset['train']['image'][1880], dtset['train']['image'][2100], dtset['train']['image'][3350], \n",
    "                         dtset['train']['image'][3880], dtset['train']['image'][4280], dtset['train']['image'][4400]]):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creació d'un nou dataset tipus diccionari\n",
    "ds = DatasetDict()\n",
    "for k,v in dtset.items():\n",
    "    ds[k] = Dataset.from_dict(v)\n",
    "\n",
    "# Funció per transformar el dataset\n",
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    # inputs = example_batch['image']\n",
    "    inputs = feature_extractor([x for x in example_batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['labels'] = example_batch['cho']\n",
    "    return inputs\n",
    "\n",
    "# Aplicar la transformació al dataset\n",
    "prepared_ds = ds.with_transform(transform)\n",
    "\n",
    "# Collate function\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d85985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la mètrica\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "# Mean Squared Error: 'mse', Mean Absolute Error: 'mae'\n",
    "metric = load_metric('mse')\n",
    "# metric = load_metric('mae')\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce120b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquesta cel·la crea un nou model amb una sola neurona a la última capa a partir del model vit\n",
    "# El nou model queda guardat al drive permanenment, per tant només cal executar-lo una vegada\n",
    "\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "# Importar el model original\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Modificar la última capa del model per a què doni una única sortida\n",
    "# model.classifier = nn.Linear(*list(model.classifier.children())[:-1], in_features=768, out_features=768)\n",
    "\n",
    "# Codi per guardar el model modificat\n",
    "model.save_pretrained(save_directory = '/content/drive/MyDrive/Treball Final de Grau/Model google_vit mod (una sola sortida)/Sense entrenar v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6dcb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar el model amb una sola neurona a la sortida sense entrenar\n",
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    '/content/drive/MyDrive/Treball Final de Grau/Model google_vit mod (una sola sortida)/Sense entrenar v1',\n",
    "    num_labels=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490180cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paràmetres de l'algorisme d'entrenament\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"/content/drive/MyDrive/Treball Final de Grau/Model google_vit mod (una sola sortida)/Entrenament 6 Nutrition5k\",\n",
    "  per_device_train_batch_size=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=4,\n",
    "  # S'ignora la següent opció, ja que només és compatible amb sistemes CUDA\n",
    "  #fp16=True,\n",
    "  save_steps=10000,\n",
    "  eval_steps=1000,\n",
    "  logging_steps=1,\n",
    "  learning_rate=1e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds['train'],\n",
    "    eval_dataset=prepared_ds['val'],\n",
    "    tokenizer=feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar tensorboard\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/content/drive/MyDrive/Treball Final de Grau/Model google_vit mod (una sola sortida)/Entrenament 6 Nutrition5k\", histogram_freq=1)\n",
    "\n",
    "%tensorboard --logdir '/content/drive/MyDrive/Treball Final de Grau/Model google_vit mod (una sola sortida)/Entrenament 6 Nutrition5k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b26e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenament del model\n",
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2afbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluació del model\n",
    "metrics = trainer.evaluate(prepared_ds['train'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar el model de l'entrenament 6\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "model = ViTForImageClassification.from_pretrained('/content/drive/MyDrive/Treball Final de Grau/Model google_vit mod (una sola sortida)/Entrenament 6 Nutrition5k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferència al model\n",
    "inputs = feature_extractor(images=dtset['test']['image'][0], return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = round(outputs.logits.item(),4)\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "print(\"CHO estimats:\", (logits+1.0)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782958f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualitzar una llista d'estimacions\n",
    "llista_mse = []\n",
    "for i in range(0,len(dtset['test']['cho'])):\n",
    "    im = dtset['test']['image'][i]\n",
    "    inputs = feature_extractor(images=im, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    # Estimació de la quanitat de carbohidrats\n",
    "    pred = round(logits.item()*100.0,4)\n",
    "    real = round((dtset['test']['cho'][i]+1.0)*100.0,4)\n",
    "    mae = round((abs(pred - real)),3)\n",
    "    llista_mse.append(mae)\n",
    "    print('mae: ', mae, 'Pred: ', pred, ' , Real: ', real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
